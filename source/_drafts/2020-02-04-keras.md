---
title: tensorflow2.0
tags:
  - 深度学习
  - tensorflow
  - keras
categories:
  - 深度学习
date: 2020-02-04 20:14:08
---
<Excerpt in index | 首页摘要> 

<!-- more -->
<The rest of contents | 余下全文>



## TensorFlow 核心库

- keras.datasets

  > 存放经典的数据集，e.g mnist、fashion_mnist

- 







## loss相关

- binary_crossentropy ：二分类问题且模型输出概率值



## 训练相关

### History对象

`model.fit()` 返回一个 `History` 对象，该对象包含一个字典，其中包含训练阶段所发生的一切事件

```python
history_dict = history.history
history_dict.keys()
# dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])
```

### 绘制训练走势图

```python
import matplotlib.pyplot as plt

# 下面4个对象的第一维度等于epoch，也就是记录了每一轮的数值
acc = history_dict['accuracy']
print(acc.shape)
val_acc = history_dict['val_accuracy']
loss = history_dict['loss']
val_loss = history_dict['val_loss']

epochs = range(1, len(acc) + 1)

# “bo”代表 "蓝点"
plt.plot(epochs, loss, 'bo', label='Training loss')
# b代表“蓝色实线”
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

plt.clf()   # 清除数字

plt.plot(epochs, acc, 'bo', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.show()
```

### 模型保存

#### 保存整个模型

调用 `model.save` 将保存模型的结构，权重和训练配置保存在单个文件/文件夹中。

整个模型可以以两种不同的文件格式（`SavedModel` 和 `HDF5`）进行保存。

##### HDF5

Keras使用 [HDF5](https://en.wikipedia.org/wiki/Hierarchical_Data_Format) 标准提供了一种基本的保存格式。

```python
# 创建并训练一个新的模型实例
model = create_model()
model.fit(train_images, train_labels, epochs=5)

# 将整个模型保存为 HDF5 文件。
# '.h5' 扩展名指示应将模型保存到 HDF5。
model.save('my_model.h5') 
```

##### SavedModel









## 预测相关

模型经过了优化，可同时对一个*批*或一组样本进行预测。因此，即便您只使用一个图像，您也需要将其添加到列表中，以mnist为例处理如下：

```python
# 一张图片
img = test_images[1]
print(img.shape) # (28, 28)
# 增加维度
img = (np.expand_dims(img,0))
print(img.shape) # (1, 28, 28)

# 取出来时就需要降维度
predictions = model.predict(img)
print(predictions[0])
```





##### 下载mnist数据集，网络失败的问题

Keras file is located into a new path in Google Cloud Storage (Before it was in AWS S3)：

```py
https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
```

When using:

```
tf.keras.datasets.mnist.load_data()
```

You can pass a `path` parameter.

`load_data()` will call `get_file()` which takes as parameter `fname`, if path is a full path and file exists, it will not be downloaded.

Example:

```py
# gsutil cp gs://tensorflow/tf-keras-datasets/mnist.npz /tmp/data/mnist.npz
# python3
>>> import tensorflow as tf
>>> path = '/tmp/data/mnist.npz'
>>> (train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data(path)
>>> len(train_images)
>>> 60000
```



